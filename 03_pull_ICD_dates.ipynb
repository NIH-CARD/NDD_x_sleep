{"metadata": {"language_info": {"name": "python", "version": "3.9.16", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}, "kernelspec": {"name": "python3", "display_name": "Python 3 (ipykernel)", "language": "python"}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "markdown", "source": "# Step 0 \n1. Create a cohort browser with the columns eid and p41270 (all ICD diagnoses) \n2. Use table exporter to export this cohort to a CSV  ", "metadata": {"tags": []}}, {"cell_type": "markdown", "source": "# Step 1 - pulling individual codes\nProcess the update the list of all ICD diagnoses into one row per code (multiple rows for one person) \n</br>\n</br>From Gracelyn_ICD10_Parsing", "metadata": {"tags": []}}, {"cell_type": "code", "source": "import pandas as pd\nimport numpy as np\nfrom time import time \nfrom multiprocessing import Pool", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "# this file is the one you made during step 0 \n!dx download 'data/ICD10_dates/icd10_codes_20231002_participant.csv'", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "#Load file created by cohort browser\ndf_orig = pd.read_csv(\"icd10_codes_20231002_participant.csv\")\ndf_orig", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "#First split by \"|\" \n#thanks StackOverflow! ^_^ https://stackoverflow.com/questions/50731229/split-cell-into-multiple-rows-in-pandas-dataframe\ntic = time()\ndf_new = (df_orig.set_index(['eid'])\n   .apply(lambda x: x.str.split('|').explode())\n   .reset_index())  \ntoc = time() \nprint(f'Time elapsed: {toc-tic} seconds')\ndf_new", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "#Now split by space\ntic = time()\ndf_new[['p41270', 'B']] = df_new['p41270'].str.split(' ', 1, expand=True)\ntoc = time()\nprint(f'Time elapsed: {toc-tic} seconds')\ndf_new", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "#Rename columns\ndf_new = df_new.rename(columns = {'eid':'ID', 'p41270':'ICD10', 'B':'description'})\ndf_new", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "df_new['ICD10-group'] = df_new['ICD10']\ndf_new[['ICD10-group', 'B']] = df_new['ICD10-group'].str.split('.', 1, expand=True)\ndf_new", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "#Keep the groups we are interested in \ngroup_list = ['G47', 'F51']\ndf_new = df_new[df_new['ICD10-group'].isin(group_list)]\ndf_new", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "df_new['ICD10-group'].value_counts()", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "for group in group_list:\n    df = df_new[df_new['ICD10-group'] == group]\n    df = df[['ID', 'ICD10']]\n    print(df.ICD10.value_counts())\n    df.to_csv(f'{group}_individual_codes.csv', header = True, index = False)", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "for group in group_list:\n    print(f'!dx upload {group}_individual_codes.csv --path data/ICD10_dates/{group}/{group}_individual_codes.csv')", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "!dx upload G47_individual_codes.csv --path data/ICD10_dates/G47/G47_individual_codes.csv\n!dx upload F51_individual_codes.csv --path data/ICD10_dates/F51/F51_individual_codes.csv", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "# Step 2 - pulling group ICD10 codes, ie. G47", "metadata": {"tags": []}}, {"cell_type": "markdown", "source": "## Need Spark Notebook ", "metadata": {}}, {"cell_type": "code", "source": "#setup - packages & env\nimport pyspark\nimport dxdata\nimport dxpy\nsc = pyspark.SparkContext()\nspark = pyspark.sql.SparkSession(sc)", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "#setup - grabbing dataset\ndispensed_database_name = dxpy.find_one_data_object(classname=\"database\", name=\"app*\", folder=\"/\", name_mode=\"glob\", describe=True)[\"describe\"][\"name\"]\ndispensed_dataset_id = dxpy.find_one_data_object(typename=\"Dataset\", name=\"app*.dataset\", folder=\"/\", name_mode=\"glob\")[\"id\"]", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "# the participant dataset is the one we ultimately want to work with \ndataset = dxdata.load_dataset(id=dispensed_dataset_id)\nparticipant = dataset[\"participant\"]", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "# Pull down the fields we need \n#Here I want G47 and F51 \nfield_names = [\"eid\", 'p131060', 'p130920']\ndf = participant.retrieve_fields(names=field_names, coding_values=\"replace\", engine=dxdata.connect())", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "# Send to Pandas \ndf = df.toPandas()", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "# Human readable columns please\ndf = df.rename(columns={'eid':'ID',\n                        'p131060':'G47_DATE',\n                        'p130920':'F51_DATE'})\n\ndf", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "group_list", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "for group in group_list:\n    test = df[~df[f'{group}_DATE'].isna()]\n    test = test[['ID', group + '_DATE']]\n    print(group, len(test))\n    test.to_csv(f'{group}_with_date.csv', header = True, index = None)", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "test", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "for group in group_list:\n    print(f'!dx upload {group}_with_date.csv --path data/ICD10_dates/{group}/{group}_with_date.csv')", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "!dx upload G47_with_date.csv --path data/ICD10_dates/G47/G47_with_date.csv\n!dx upload F51_with_date.csv --path data/ICD10_dates/F51/F51_with_date.csv", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "# Step 3 -- creating individual ICD10 files, ie. G47.3", "metadata": {"tags": []}}, {"cell_type": "code", "source": "icd = 'G47'\ngroup = pd.read_csv(f'{icd}_with_date.csv')\ngroup = group[['ID', f'{icd}_DATE']]\nindividual = pd.read_csv(f'{icd}_individual_codes.csv')\nprint(icd)\nprint('group', len(group))\nprint('individual', len(individual))", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "print(group.head())", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "print(individual.head())", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "#Find any IDs with more than 1 code\nindividual.ID.value_counts()", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "df = group.merge(individual, left_on = 'ID', right_on = 'ID', how = 'left')\ndf", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "test = df[~df['ICD10'].isna()]\ncodes_list = list(set(list(test['ICD10'])))\ncodes_list", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "codes_with_data = []\nfor code in codes_list:\n    df2 = df[df['ICD10'] == code]\n    df2[f'{code}_DATE'] = df2[f'{icd}_DATE']\n    df2 = df2[['ID', code + '_DATE']]\n    print(code, len(df2))\n    \n    #Only create files for codes with at least 5 samples\n    \n    if len(df2) > 4:\n        codes_with_data.append(code)\n        df2.to_csv(f'{code}_with_date.csv', header = True, index = None)\n    else:\n        pass\n    ", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "for code in codes_with_data:\n    print(f'!dx upload {code}_with_date.csv --path data/ICD10_dates/{icd}/{code}_with_date.csv')", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "!dx upload G47.2_with_date.csv --path data/ICD10_dates/G47/G47.2_with_date.csv\n!dx upload G47.3_with_date.csv --path data/ICD10_dates/G47/G47.3_with_date.csv\n!dx upload G47.0_with_date.csv --path data/ICD10_dates/G47/G47.0_with_date.csv\n!dx upload G47.4_with_date.csv --path data/ICD10_dates/G47/G47.4_with_date.csv\n!dx upload G47.1_with_date.csv --path data/ICD10_dates/G47/G47.1_with_date.csv\n!dx upload G47.8_with_date.csv --path data/ICD10_dates/G47/G47.8_with_date.csv\n!dx upload G47.9_with_date.csv --path data/ICD10_dates/G47/G47.9_with_date.csv", "metadata": {"trusted": true, "tags": []}, "execution_count": null, "outputs": []}]}